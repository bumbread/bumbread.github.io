<!DOCTYPE html><html><head><meta charset=utf-8><meta name=referrer content=no-referrer><meta name=viewport content="width=device-width, initial-scale=0.7"><link rel=stylesheet href=/styles.css><link rel=favicon href=/favicon.ico><link rel=apple-touch-icon href=/favicon.ico><script src=/coloring.js defer></script><body><h1 id=unicode-in-programming-languages>Unicode in programming languages.</h1><p>It has become a trend in recent years to support unicode in programming languages. Java, Python, JavaScript, Go, and lots of other new languages support unicode in some form.<p>In the older times lanugages used to support only 127(±) ASCII characters. Some languages could handle ANSI extensions in the source files. The applications that used them in strings were not portable across different countries, and sometimes within the same country if they use several languages, or one languages represented by different encodings. You could only make a portable product without hacks if you used the 127-ASCII characters. And you could only make a translation of your product if you used the other 128 ANSI extended characters.<p>Unicode changed the game. Most major operating systems support a decent chunk of unicode. Now you can write a single program that, when tries to display a string in a given language, will display the same string on any other computer! That makes it easy for the countries that used sevearal incompatible encodings at the same time.<p>But with a few good game-changers, unicode also brought a few problems. In this article I would like to explore pros and cons of supporting various unicode features in a programming language, how it can be done in different ways and which tradeoffs it will present to you, as a language developer. I will try to be unbiased as much as possible. I will try only stating the objective effects of particular choices and some subjective experiences, but you should note that <em>there is no general solution</em>. Pick one for yourself, I shall only provide you some food for thought.<p>In this article I will be using the word "european" to mean "european except english", and "english" to refer to both UK and US variants of the language (since they use the same characters).<p>Before we start talking I would like to introduce you to the term <em>unicode</em> and how the <em>UTF</em> encodings work. This will be important in our conversation. If you already know how UTF-8, UTF-16 and UTF-32 characters are encoded, then you can skip the following section.<h2 id=unicode>Unicode</h2><h2 id=strings>Strings</h2><p>The first paragraphs of the article were devoted to a problem of strings in your programming lanugage. Unless you are making a language for very specific purpose I wouldn't recommend removing/not adding support for unicode strings. The strings are the parts of the program that can be displayed to a user, and they don't <em>have</em> to be able to know English to communicate to your program.<p>Various operating system and libraries support different formats of unicode encodings. As far as I'm aware Linux kernel takes in UTF-8 strings, because they are easy to scan through in an ASCII-compatible way. Windows uses either UCS-2, but Windows 10 versions have support for UTF-8 codepage <code>65001</code>. So using UTF-8 everywhere might be a sane bet, if you don't want to introduce several types of strings into your language or slow down your code by converting formats when talking to the OS.<p>The tradeoff is that UTF-8 strings aren't easy for a beginner to scan through. A few library calls like <code>decode_utf8_rune_at</code> may be useful, but compared to using simple O(1) accessor (viz. <code>str[i]</code>) it is still complicated. In contrast, UTF-16 supports almost every european character and most of the CJK (Chinese-Japanese-Korean) characters. UTF-16 doesn't cover emoji's so if further simplicity is required, you may want to consider using UTF-32.<p>Note that, however UTF-32 adds a significant memory overhead. +75% overhead for english, +50% for european characters and most CJK characters. UTF-16 is a perfect balance for most of the european languages. UTF-8 provides +25% overhead for european characters, but perfect for applications that extensively use english and need ASCII compatibility.<p>Your language may be aimed at a more precise control over strings, so it might be useful to define different literals for strings in various UTF formats. viz.:<pre><code>let utf8string = u8"строка";
let utf16string = u16"文字列"
let utf32string = u32"waste of space";
</code></pre><p>We should draw a clear line between <em>source encoding</em> and <em>string encoding</em>. If your program source code is encoded via UTF-8 it doesn't imply that the strings in the program are also UTF-8. At least this shouldn't be the implication. Although it is technically possible to add a different category of strings, that will be taken <em>literally</em>, i.e. byte-by-byte from the source encoding. In such cases the both the user and the programmer must be careful not to input a character which has a byte matching with raw literal's border character.<pre><code>`this строка matches byte-by-byte with source
for example if it is encoded via windows 1256 encoding
the display of this string will be broken unless
output to a terminal that has codepage 1256 on.`
</code></pre><h2 id=character-literals>Character literals</h2><p>Before I introduce you to the main part of this section, I want you to look at the following piece of code (that are located in a statement context) and tell me which of the two lines will compile, if any:<pre><code>var b = 'だ';
var c = 'だ';
</code></pre><p>Even if both lines look identical to you, they are, in fact, different. In the first line we have <em>japanese "da" hiragana</em>. In the second line we have <em>japanese "ta" hiragana</em> followed by <em>japanese dakuten mark</em> (a diacritic that makes the consonant sound "soft").<p>So since Go does not normalize unicode strings, the second string, in Go compiler's opinion contains two characters. I will explain why this might matter.<p>Japanese users do not enter the text the same way that european and english people do. They use a special window called Input Method Editor (IME) (usually come with the operating system).<p>Within IME there are two ways of entering japanese text. First one is <em>romazi input</em>. The input of the character <code>だ</code> will be performed by typing english letter <code>d</code> followed by english letter <code>a</code>. The sequence of characters "da" will be highlighted by the window and a few alternatives (kanji and katakana writings) will be present. The user can chose one of the alternatives and then press <code>Enter</code>. The string <code>だ</code>, consisting of a single codepoint will be send to the application via IME events in a message processing queue.<p>The second way is <em>kana input</em>. Unlike romazi input, where you input using english characters, in kana input you would input katakana characters. The IME window is still shown, showing you various alternative scripts. But the traditional keyboards doesn't have 50 keys, one for each kana. Instead they have keys for "clear" characters, such as <code>た</code>, and a separate diacritic mark that looks like a double quote. This reduces the number of keys in about a half. But surprise, when you enter <code>た</code>, followed by dakuten character, the IME window doesn't send the single codepoint for <code>だ</code>. It sends two codepoints, one for "ta" and another for the dakuten.<p>The difficulty is that not every japanese person can (in fact the majority can not) input a single character inside Go's literal!<p>I was pretty sure that the same thing happens with spanish language an the <code>ñ</code> character, however in practice spanish keyboards don't have a separate key for tilde.<p>On the other hand, unicode normalization procedure may be introduce a small performance tradeoff for compilers. Depending on a particular kind of normalization performed the results may also change the results. For example, if normalization results in a <em>decomposed string</em>, meaning that a single character (viz. <code>だ</code>) becomes a sequence of character and diacritics in a certain order (viz. <code>た</code> + dakuten).<h2 id=variables>Variables</h2><p>String literals and character literals have pretty trivial problems, compared to unicode support in identifiers.<h3 id=1-disabling-unicode-identifiers>1. Disabling unicode identifiers</h3><p>Not supporting unicode identifiers is not an excuse for not doing unicode parsing. It matters during the error handling stage. Consider this situation with a word <code>dеf</code>, where <code>e</code> is a cyrillic character.<pre><code class="dРµf language-dРµf"> ^ 'Р' invalid character
def
 ^ 'е' invalid character
dеf
 ^ 'u+D0B5' invalid character
</code></pre><p>The first error message is what happens if you assume that not supporting unicode implies that the input will not be a unicode string, and you just handle the ASCII. The first byte of UTF-8 sequence for cyrillic <code>е</code> character is <code>D0</code>. In codepage 1251, the most common encoding used in russia that character is <code>Р</code> (cyrillic R).<p>You can actually assume ASCII, but on windows make sure that your user has codepage <code>65001</code> enabled. In that case your error message becomes like the second one above. This is not helpful at all! It looks like compiler is disagreeing with the specification of the language itself or just randomly started trolling you.<p>Therefore if you're going to <strong>disable</strong> support for unicode you have to do some <strong>utf-8 parsing</strong>, at least for the error messages.<h3 id=2-rationale-for-supportingnot-supporting-the-unicode-identifiers>2. Rationale for supporting/not supporting the unicode identifiers</h3><p>Why would anyone care about the unicode identifiers? Other countries, of course. If your language is meant to be used to teach at foreign schools or other institutions, or to be used by non-professional individuals, then unicode identifiers may be what you want to have a support on in your language.<p>Even if you disable the unicode support in identifiers, a lot of people will be able to come up with english transliterations.<p>There is virtually zero chance that including unicode support will do much harm to the language ecosystem. Every foreign school/university teaches future programmers that they should always write english names for their variables and functions. Most of the universities include an additional english course.<p>Even if you disable identifiers for that particular reason there's no way that will not force people to use transliterations/romanizations.<p>Including unicode identifiers, however, makes one particular annoyance with your language possible. Have you ever spend an hour trying to fix a <em>syntax error</em>? Well consider following Python code and tell me what is the error:<pre><code>dеf func(x):
    ^^^^  
    unexpected identifier

  return x+1;
</code></pre><p>This is a real code and a real error.<p>Python thinks that <code>dеf</code> is an identifier (it is), but identfiers can not be followed by other identifiers directly. The core of the error is that the <code>е</code> letter is a cyrillic one, not ASCII letter.<p>Me and a few of my russian friends turn out to have been experiencing this "bug", and let me tell you, it's the worst kind of bug for two reasons: first, it is rare. You never expect this particular syntax error to occur. Which means it will be the last thing you will try, thereby wasting a lot of time. Secondly, it is real. Having wrong keyboard layout usually implies that the characters you type will be wrong. It is not the case with cyrillic <code>с</code>. On russian keyboards <code>с</code> is located at the same key as the english <code>c</code>.<p>You may want consider forbidding mixing up english and other foreign characters in the same identifier. Treat this as a lexing error. This can make the error message a bit nicer:<h3 id=3-which-characters-to-enable>3. Which characters to enable</h3><h2 id=links>Links</h2><p><a href="Unicode standard annex: unicode normalization">https://unicode.org/reports/tr15/</a> <a href="Unicode standard annex: unicode identifier syntax">http://unicode.org/reports/tr31</a> <a href="Rust RFC: non-ascii identifiers">https://rust-lang.github.io/rfcs/2457-non-ascii-idents.html</a> <a href="Zig issues: source encoding">https://github.com/ziglang/zig/issues/663</a> <a href="Zig issues: unicode identifiers">https://github.com/ziglang/zig/issues/3947</a>